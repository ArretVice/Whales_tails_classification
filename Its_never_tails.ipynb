{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Its never tails.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArretVice/Whales_tails_classification/blob/master/Its_never_tails.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pO_hhSzWmK_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ]
    },
    {
      "metadata": {
        "id": "DR-p9cR9igBj",
        "colab_type": "code",
        "outputId": "834a98b1-f77b-4e5c-edbf-e54bf613aba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import zipfile\n",
        "from PIL import Image, ImageOps\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "# keras stuff\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input, add\n",
        "from keras.layers import Activation, LeakyReLU, ELU, BatchNormalization, Lambda\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l1_l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4wC3ifiWjscg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Download and unzip the data for competition**"
      ]
    },
    {
      "metadata": {
        "id": "dl4XWgaTj5OE",
        "colab_type": "code",
        "outputId": "2328dc08-8cab-4273-c619-cd2330c96535",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "cell_type": "code",
      "source": [
        "# downloading\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "kaggle_token=files.upload() # select the kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle competitions download -c humpback-whale-identification\n",
        "\n",
        "# unpacking and delete initial .zip files\n",
        "\n",
        "archive_types=['train','test']\n",
        "for archive_type in archive_types:\n",
        "    with zipfile.ZipFile(archive_type+'.zip') as z:\n",
        "        os.chdir('../content')\n",
        "        try:\n",
        "            os.mkdir(archive_type)\n",
        "        except:\n",
        "            pass    \n",
        "        os.chdir(archive_type)\n",
        "        print(f'Extracting {archive_type} data...')\n",
        "        z.extractall()\n",
        "        print(archive_type.capitalize()+' data extracted and ready.')\n",
        "        os.chdir('..')\n",
        "        os.remove(archive_type+'.zip')\n",
        "os.mkdir('saved_weights')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.1.1)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d99b655-68ca-43d5-95ee-314996646dcd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5d99b655-68ca-43d5-95ee-314996646dcd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/498k [00:00<?, ?B/s]\n",
            "100% 498k/498k [00:00<00:00, 63.0MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/594k [00:00<?, ?B/s]\n",
            "100% 594k/594k [00:00<00:00, 80.7MB/s]\n",
            "Downloading test.zip to /content\n",
            " 99% 1.34G/1.35G [00:16<00:00, 73.1MB/s]\n",
            "100% 1.35G/1.35G [00:16<00:00, 85.4MB/s]\n",
            "Downloading train.zip to /content\n",
            "100% 4.15G/4.16G [01:14<00:00, 76.8MB/s]\n",
            "100% 4.16G/4.16G [01:14<00:00, 59.6MB/s]\n",
            "Extracting train data...\n",
            "Train data extracted and ready.\n",
            "Extracting test data...\n",
            "Test data extracted and ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2blgFo_jNWKu",
        "colab_type": "code",
        "outputId": "3920e66d-cba6-41da-83fa-ffe509161152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'train',\n",
              " 'saved_weights',\n",
              " 'sample_submission.csv',\n",
              " 'train.csv',\n",
              " 'test',\n",
              " 'kaggle.json',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "_J0kzgkGmezt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load and explore data**"
      ]
    },
    {
      "metadata": {
        "id": "SQMzFoRXmcru",
        "colab_type": "code",
        "outputId": "fdf52b4e-7762-4bf2-9e77-97bc97e07dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('train.csv')\n",
        "df=df.rename(columns={'Image':'image'})\n",
        "unique_labels=sorted(set(df.Id.values))\n",
        "Id_to_label_dict={key: value for value, key in enumerate(unique_labels)}\n",
        "df['whale_type']=df.Id.apply(lambda x: Id_to_label_dict[x])\n",
        "df.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>Id</th>\n",
              "      <th>whale_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23272</th>\n",
              "      <td>ea685fbba.jpg</td>\n",
              "      <td>w_60cf87c</td>\n",
              "      <td>1870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5272</th>\n",
              "      <td>35fb1669b.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5452</th>\n",
              "      <td>37bc1b579.jpg</td>\n",
              "      <td>w_778e474</td>\n",
              "      <td>2342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25210</th>\n",
              "      <td>fe57772d4.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17446</th>\n",
              "      <td>af0194be3.jpg</td>\n",
              "      <td>new_whale</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               image         Id  whale_type\n",
              "23272  ea685fbba.jpg  w_60cf87c        1870\n",
              "5272   35fb1669b.jpg  new_whale           0\n",
              "5452   37bc1b579.jpg  w_778e474        2342\n",
              "25210  fe57772d4.jpg  new_whale           0\n",
              "17446  af0194be3.jpg  new_whale           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "uQlApSqGiqCw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # stolen from here:\n",
        "# # https://www.kaggle.com/hrmello/flow-from-dataframe-a-memory-friendly-approach\n",
        "\n",
        "\n",
        "# # rewrite in SSF mode\n",
        "# images=df[['image','Id']].sample(5).values.tolist()\n",
        "# fig, m_axs = plt.subplots(1, len(images), figsize = (20, 10))\n",
        "\n",
        "# for ii, c_ax in enumerate(m_axs):\n",
        "#     image_to_show=Image.open('train/'+images[ii][0]).convert('L')\n",
        "#     c_ax.imshow(image_to_show)\n",
        "#     c_ax.set_title(images[ii][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xdyx8KYuAAvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Custom functions for image preprocessing**"
      ]
    },
    {
      "metadata": {
        "id": "peasjaFuAF3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def custom_resize_image(full_image_path, target_width_height, epsilon=0.005):\n",
        "    \n",
        "    '''\n",
        "    Resize image to target size, preserving aspect ratio by adding \n",
        "    black borders where necessary.\n",
        "    '''\n",
        "    \n",
        "    best_ratio=target_width_height[0]/target_width_height[1]\n",
        "    image_to_show=Image.open(full_image_path).convert('L')\n",
        "    \n",
        "    # add border to image for it to have aspect ratio close to <best_ratio>\n",
        "    if abs(image_to_show.width/image_to_show.height-best_ratio)>epsilon:\n",
        "        target_height=image_to_show.height\n",
        "        target_width=image_to_show.width\n",
        "        if image_to_show.width>image_to_show.height*best_ratio:\n",
        "            target_height=int(image_to_show.width/best_ratio)\n",
        "        else:\n",
        "            target_width=int(image_to_show.height*best_ratio)\n",
        "        top_bottom_borders=(target_height-image_to_show.height)//2\n",
        "        sides_border=(target_width-image_to_show.width)//2\n",
        "        image_to_show=ImageOps.expand(image_to_show,\n",
        "                                      border=(sides_border,top_bottom_borders))\n",
        "\n",
        "    # resize to target size\n",
        "    image_to_show=image_to_show.resize(target_width_height)\n",
        "    return image_to_show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L778sX7vA2T7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_image(image_to_show, num_rotations=5,\n",
        "                  min_rotation=-15, max_rotation=15,\n",
        "                  enable_upside_down=True, enable_rotations=True,\n",
        "                  enable_mirroring=True):\n",
        "    \n",
        "    '''\n",
        "    Augment input image with mirroring, flipping and rotations.\n",
        "    Image's pixel values are normalized with /255.\n",
        "    '''\n",
        "    \n",
        "    # list with prepared images\n",
        "    prepared_images=[]\n",
        "\n",
        "    # initial image\n",
        "    initial=(np.array(image_to_show)/255).reshape(\n",
        "        (image_to_show.size[1], image_to_show.size[0], 1))\n",
        "    prepared_images.append(initial)\n",
        "\n",
        "    # mirroring (left to right)\n",
        "    if enable_mirroring:\n",
        "        mirrored=(np.array(ImageOps.mirror(image_to_show))/255).reshape(\n",
        "        (image_to_show.size[1], image_to_show.size[0], 1))\n",
        "        prepared_images.append(mirrored)\n",
        "\n",
        "    # flipping (upside down)\n",
        "    if enable_upside_down:\n",
        "        flipped=(np.array(ImageOps.flip(image_to_show))/255).reshape(\n",
        "        (image_to_show.size[1], image_to_show.size[0], 1))\n",
        "        prepared_images.append(flipped)\n",
        "\n",
        "    # rotations\n",
        "    if enable_rotations:\n",
        "        rotations=np.linspace(min_rotation, max_rotation,\n",
        "                              num_rotations).astype(int)\n",
        "        \n",
        "        for rotation in rotations:\n",
        "            rotated=(np.array(image_to_show.rotate(rotation))/255).reshape(\n",
        "        (image_to_show.size[1], image_to_show.size[0], 1))\n",
        "            prepared_images.append(rotated)\n",
        "    \n",
        "    return np.stack(prepared_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVKGE4pS5Dtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomly_augment_image(image_to_show):\n",
        "    \n",
        "    '''\n",
        "    Randomly augment image so it doesn't exactly look like original image.\n",
        "    This is used when there is only one image of a class available.\n",
        "    '''\n",
        "    \n",
        "    # randomly mirror\n",
        "    mirrored=False\n",
        "    option=[True, False]\n",
        "    if random.choice(option):\n",
        "        image_to_show=ImageOps.mirror(image_to_show)\n",
        "        mirrored=True\n",
        "        \n",
        "    # randomly rotate\n",
        "    possible_rotations=list(range(-15, 16))\n",
        "    if not mirrored:\n",
        "        # this way if image is not mirrored, it will at least be rotated\n",
        "        possible_rotations.remove(0)\n",
        "        \n",
        "    rotation=random.choice(possible_rotations)\n",
        "    image_to_show=image_to_show.rotate(rotation)\n",
        "    \n",
        "#     # randomly flip - this one is to be tested\n",
        "#     if random.choice(option):\n",
        "#         image_to_show=ImageOps.flip(image_to_show)\n",
        "#         mirrored=True\n",
        "        \n",
        "    return image_to_show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdSRN45GBaes",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def chunk_iterator(iterable, chunk_len):\n",
        "    \n",
        "    '''Simple iterator to help iterate over mini-batches.'''\n",
        "    \n",
        "    stack=[]\n",
        "    for item in iterable:\n",
        "        if len(stack)>=chunk_len:\n",
        "            yield stack\n",
        "            stack=[]\n",
        "        stack.append(item)\n",
        "    else:\n",
        "        yield stack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-SoKekaBpzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pair_generator(df, image_folder, target_w_h, n_rota, min_rota, max_rota,\n",
        "                   en_updown, en_rota, en_mirror):\n",
        "    \n",
        "    '''\n",
        "    Generates pairs of pairs of images - one pair of the same type,\n",
        "    one pair of different types (any_whale vs any_whale)\n",
        "    Returns list of pairs of image file names with labels 0 or 1.\n",
        "    '''\n",
        "    \n",
        "    whale_types=df['whale_type'].values.tolist()\n",
        "    \n",
        "    while True:\n",
        "        random.shuffle(whale_types)\n",
        "        \n",
        "        for wtype in whale_types:\n",
        "            \n",
        "            # revisit this part (because recreating lists on each iteration) #\n",
        "            current_type_list=df[df['whale_type']==wtype]['image'].values.tolist()\n",
        "            other_types_list=df[df['whale_type']!=wtype]['image'].values.tolist()\n",
        "            # ############################################################## #\n",
        "            \n",
        "            x1, x2, y = {}, {}, {}\n",
        "            for t in ['pos','neg']:\n",
        "                flag=False\n",
        "                x1[t]=random.choice(current_type_list)\n",
        "                \n",
        "                if t=='pos':\n",
        "                    x2[t]=random.choice(current_type_list)\n",
        "                    y[t]=1\n",
        "                    # random augmentation flag if image is the same\n",
        "                    if x2[t]==x1[t]: flag=True\n",
        "\n",
        "                else:\n",
        "                    x2[t]=random.choice(other_types_list)\n",
        "                    y[t]=0\n",
        "                    \n",
        "                                    \n",
        "                x1[t]=custom_resize_image(image_folder+x1[t], target_w_h)\n",
        "                \n",
        "                x1[t]=augment_image(x1[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "                \n",
        "                \n",
        "                x2[t]=custom_resize_image(image_folder+x2[t], target_w_h)\n",
        "                \n",
        "                # apply random augmentation if image is the same\n",
        "                if flag:\n",
        "                    x2[t]=randomly_augment_image(x2[t])\n",
        "                \n",
        "                x2[t]=augment_image(x2[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "                \n",
        "                y[t]=y[t]*np.ones((len(x1[t]),1))\n",
        "                \n",
        "                yield [x1[t], x2[t]], y[t]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AyHU-5UT12pw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pair_generator_v2(df, image_folder, target_w_h, n_rota, min_rota, max_rota,\n",
        "                   en_updown, en_rota, en_mirror):\n",
        "    \n",
        "    '''\n",
        "    Generates pairs of pairs of images \n",
        "    (one pair of the same type, one pair of different types):\n",
        "    1. known_whale vs known_whale\n",
        "    2. known_whale vs any_whale (both known and unknown or 'new_whale')\n",
        "    Returns list of pairs of image file names with labels 0 or 1.\n",
        "    '''\n",
        "\n",
        "    any_whales=df['whale_type'].values.tolist()\n",
        "    known_whales=df[df['whale_type']!=0]\n",
        "    known_whales=known_whales['whale_type'].values.tolist()\n",
        "    possible_options=['known_vs_known','known_vs_any']\n",
        "    random.shuffle(known_whales)\n",
        "    random.shuffle(any_whales)\n",
        "    \n",
        "    while True:\n",
        "        for option in possible_options:\n",
        "\n",
        "            if option=='known_vs_known':\n",
        "                wtype=random.choice(known_whales)\n",
        "            else:\n",
        "                wtype=random.choice(any_whales)\n",
        "\n",
        "            current_type_list=df[df['whale_type']==wtype]['image'].values.tolist()\n",
        "            other_types_list=df[df['whale_type']!=wtype]['image'].values.tolist()\n",
        "\n",
        "            x1, x2, y = {}, {}, {}\n",
        "\n",
        "            for t in ['pos','neg']:\n",
        "\n",
        "                flag=False\n",
        "                x1[t]=random.choice(current_type_list)\n",
        "\n",
        "                if t=='pos':\n",
        "                    x2[t]=random.choice(current_type_list)\n",
        "                    y[t]=1\n",
        "                    # random augmentation flag if image is the same\n",
        "                    if x2[t]==x1[t]: flag=True\n",
        "\n",
        "                else:\n",
        "                    x2[t]=random.choice(other_types_list)\n",
        "                    y[t]=0\n",
        "\n",
        "\n",
        "                x1[t]=custom_resize_image(image_folder+x1[t], target_w_h)\n",
        "\n",
        "                x1[t]=augment_image(x1[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "\n",
        "\n",
        "                x2[t]=custom_resize_image(image_folder+x2[t], target_w_h)\n",
        "\n",
        "                # apply random augmentation if image is the same\n",
        "                if flag:\n",
        "                    x2[t]=randomly_augment_image(x2[t])\n",
        "\n",
        "                x2[t]=augment_image(x2[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "\n",
        "                y[t]=y[t]*np.ones((len(x1[t]),1))\n",
        "\n",
        "                yield [x1[t], x2[t]], y[t]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJwX1h7ZChIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pair_generator_v3(df, image_folder, target_w_h, n_rota, min_rota, max_rota,\n",
        "                   en_updown, en_rota, en_mirror):\n",
        "\n",
        "    '''\n",
        "        Generates pairs of pairs of images \n",
        "        (one pair of the same type, one pair of different types):\n",
        "        1. known_whale vs known_whale\n",
        "        2. known_whale vs any_whale (both known and unknown or 'new_whale')\n",
        "        3. known_whale vs unknown_whale ('new_whale' class in dataset)\n",
        "        Returns list of pairs of image file names with labels 0 or 1.\n",
        "    '''\n",
        "\n",
        "    any_whales=df['whale_type'].values.tolist()\n",
        "    known_whales=df[df['whale_type']!=0]\n",
        "    known_whales=known_whales['whale_type'].values.tolist()\n",
        "    unknown_whales=0\n",
        "\n",
        "    possible_options=['known_vs_known','known_vs_any','known_vs_unknown']\n",
        "\n",
        "    random.shuffle(known_whales)\n",
        "    random.shuffle(any_whales)\n",
        "\n",
        "    while True:\n",
        "        for option in possible_options:\n",
        "\n",
        "            if option=='known_vs_known':\n",
        "                wtype=random.choice(known_whales)\n",
        "            elif option=='known_vs_unknown':\n",
        "                wtype=0\n",
        "            else:\n",
        "                wtype=random.choice(any_whales)\n",
        "\n",
        "            current_type_list=df[df['whale_type']==wtype]['image'].values.tolist()\n",
        "            other_types_list=df[df['whale_type']!=wtype]['image'].values.tolist()\n",
        "            \n",
        "            x1, x2, y = {}, {}, {}\n",
        "\n",
        "            for t in ['pos','neg']:\n",
        "\n",
        "                flag=False\n",
        "                x1[t]=random.choice(current_type_list)\n",
        "                \n",
        "                if t=='pos':\n",
        "                    x2[t]=random.choice(current_type_list)\n",
        "                    y[t]=1\n",
        "                    # random augmentation flag if image is the same\n",
        "                    if x2[t]==x1[t]: flag=True\n",
        "\n",
        "                else:\n",
        "                    x2[t]=random.choice(other_types_list)\n",
        "                    y[t]=0\n",
        "                    \n",
        "                                    \n",
        "                x1[t]=custom_resize_image(image_folder+x1[t], target_w_h)\n",
        "                \n",
        "                x1[t]=augment_image(x1[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "                \n",
        "                \n",
        "                x2[t]=custom_resize_image(image_folder+x2[t], target_w_h)\n",
        "                \n",
        "                # apply random augmentation if image is the same\n",
        "                if flag:\n",
        "                    x2[t]=randomly_augment_image(x2[t])\n",
        "                \n",
        "                x2[t]=augment_image(x2[t],\n",
        "                                    num_rotations=n_rota,\n",
        "                                    min_rotation=min_rota,\n",
        "                                    max_rotation=max_rota, \n",
        "                                    enable_upside_down=en_updown,\n",
        "                                    enable_rotations=en_rota, \n",
        "                                    enable_mirroring=en_mirror)\n",
        "                \n",
        "                y[t]=y[t]*np.ones((len(x1[t]),1))\n",
        "                \n",
        "                yield [x1[t], x2[t]], y[t]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwnlk5Y5EI-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating model**"
      ]
    },
    {
      "metadata": {
        "id": "4zIsYB7wENlt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    Model parameters:"
      ]
    },
    {
      "metadata": {
        "id": "mzF4g3JDD2T1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TARGET_W_H = (600, 300) # img will be resized to this size to match input layer\n",
        "REG=l1_l2(0.01, 0.001) # L1 and L2 regularization\n",
        "\n",
        "EN_UPDOWN = False # add upside-down image to training batch\n",
        "EN_MIRROR = True # add mirrored image to training batch\n",
        "\n",
        "EN_ROTA = False   # add rotated images to training batch \n",
        "N_ROTA = 6       # number of images to add\n",
        "MIN_ROTA = -10   # min angle to rotate\n",
        "MAX_ROTA = 10    # max angle to rotate\n",
        "\n",
        "#DATA = df[df['whale_type']!=0] # only known whales\n",
        "DATA = df # all whales"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRLBzD-XF2lQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    Model architecture:"
      ]
    },
    {
      "metadata": {
        "id": "-haxKO2aEQ9B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# base siamese model\n",
        "encoder_part=Sequential()\n",
        "\n",
        "# encoder branch of a model\n",
        "\n",
        "encoder_part.add(Conv2D(32, kernel_size=(5,5), padding='valid', strides=(1,1),\n",
        "                        kernel_regularizer=REG,\n",
        "                        input_shape = (TARGET_W_H[1], TARGET_W_H[0], 1) ))\n",
        "encoder_part.add(BatchNormalization())\n",
        "encoder_part.add(Activation('relu'))\n",
        "encoder_part.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "\n",
        "encoder_part.add(Conv2D(64, kernel_size=(5,5), padding='valid', strides=(1,1),\n",
        "                       kernel_regularizer=REG))\n",
        "encoder_part.add(BatchNormalization())\n",
        "encoder_part.add(Activation('relu'))\n",
        "encoder_part.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "encoder_part.add(Conv2D(128, kernel_size=(3,3), padding='valid', strides=(1,1),\n",
        "                       kernel_regularizer=REG))\n",
        "encoder_part.add(BatchNormalization())\n",
        "encoder_part.add(Activation('relu'))\n",
        "encoder_part.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "encoder_part.add(Conv2D(256, kernel_size=(3,3), padding='valid', strides=(1,1),\n",
        "                       kernel_regularizer=REG,))\n",
        "encoder_part.add(BatchNormalization())\n",
        "encoder_part.add(Activation('relu'))\n",
        "encoder_part.add(MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "encoder_part.add(Flatten())\n",
        "#encoder_part.add(Dropout(0.2))\n",
        "encoder_part.add(Dense(256))\n",
        "encoder_part.add(BatchNormalization())\n",
        "encoder_part.add(Activation('sigmoid'))\n",
        "\n",
        "# pairs of images\n",
        "input_image_1 = Input((TARGET_W_H[1], TARGET_W_H[0], 1))\n",
        "input_image_2 = Input((TARGET_W_H[1], TARGET_W_H[0], 1))\n",
        "\n",
        "encoded_image_1 = encoder_part(input_image_1)\n",
        "encoded_image_2 = encoder_part(input_image_2)\n",
        "\n",
        "# L1 distance layer between the two encoded outputs\n",
        "l1_distance_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
        "l1_distance = l1_distance_layer([encoded_image_1, encoded_image_2])\n",
        "\n",
        "# prediction\n",
        "prediction = Dense(units=1, activation='sigmoid')(l1_distance)\n",
        "siamese_model = Model(inputs=[input_image_1, input_image_2],\n",
        "                      outputs=prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpfWcKfXOQ1w",
        "colab_type": "code",
        "outputId": "1f35e05b-37b3-4af5-86b4-a6f7bd982a76",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# upload pretrained model (optional)\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ecaa8b2-992e-48f4-8dd0-7205a8e1d540\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0ecaa8b2-992e-48f4-8dd0-7205a8e1d540\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model_1024.hdf5 to model_1024.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iVpm2q6LNhk5",
        "colab_type": "code",
        "outputId": "a896360e-f509-426b-c905-b614511ba5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# load model if its available\n",
        "try:\n",
        "    siamese_model=load_model('saved_weights/weights.hdf5')\n",
        "    print('Model loaded')\n",
        "except:\n",
        "    print('Unable to load saved model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WE1O6az-e-GO",
        "colab_type": "code",
        "outputId": "0c6eb04b-b0ea-460f-a93b-51c4df298ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "siamese_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 300, 600, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           (None, 300, 600, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       (None, 256)          37124480    input_11[0][0]                   \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 256)          0           sequential_6[1][0]               \n",
            "                                                                 sequential_6[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1)            257         lambda_6[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 37,124,737\n",
            "Trainable params: 37,123,265\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V7LVuClOF5tK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt=Adam(lr=1e-3, decay=1e-9)\n",
        "chkp = ModelCheckpoint(monitor='binary_accuracy',\n",
        "                       mode='max',\n",
        "                       filepath='saved_weights/weights.hdf5',\n",
        "                       verbose=1,\n",
        "                       save_best_only=True)\n",
        "\n",
        "siamese_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        "    optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HFasB2cHkN6",
        "colab_type": "code",
        "outputId": "fb251ccf-f9d2-430b-f1e5-f2d364e947d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "cell_type": "code",
      "source": [
        "siamese_model.fit_generator(\n",
        "    pair_generator_v2(DATA, 'train/', TARGET_W_H, N_ROTA, MIN_ROTA,\n",
        "                   MAX_ROTA, EN_UPDOWN, EN_ROTA, EN_MIRROR),\n",
        "    epochs=50,\n",
        "    steps_per_epoch=5000,\n",
        "    callbacks=[chkp])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3257/5000 [==================>...........] - ETA: 5:20 - loss: 19.4887 - binary_accuracy: 0.4986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-3ad102c54ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     callbacks=[chkp])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zoB6urB7nd6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download saved model\n",
        "files.download('saved_weights/weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYvRIxMZ-xDO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Encoding training images**"
      ]
    },
    {
      "metadata": {
        "id": "4tZMtIDG6gbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# getting encoder part from model\n",
        "encoder=siamese_model.layers[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dp41yA9sH3pz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode each image using encoder part of siamese model\n",
        "def encode_image(image, path='train/'):\n",
        "    img=custom_resize_image(path+image, TARGET_W_H)\n",
        "    img=np.array(img)/255\n",
        "    img=img.reshape(1, TARGET_W_H[1], TARGET_W_H[0], 1)\n",
        "    pred=encoder.predict(img)\n",
        "    pred=pred.reshape(-1)\n",
        "    return pred  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLQ2n4tcKN1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adding an encoding column to data frame\n",
        "df['encoding']=df['image'].map(encode_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WZqrNVdhe3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sort by whale Id\n",
        "df=df[['Id','encoding']]\n",
        "df=df.sort_values('Id').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MG71aDJCKSvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save encoded df\n",
        "df.to_csv('encoded_df.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNjD15v6SZyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download saved data frame for future use\n",
        "files.download('encoded_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5iMstgcivwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QsaZnHrHSqNN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Predicting on test data**"
      ]
    },
    {
      "metadata": {
        "id": "lFD6DNwNjHIQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    Encode test images"
      ]
    },
    {
      "metadata": {
        "id": "Dvbusdf9WIXx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_images=sorted(os.listdir('test'))\n",
        "df_test=pd.DataFrame()\n",
        "df_test['Image']=test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hdnqSpRhYUeq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_test_image(image, path='test/'):\n",
        "    img=custom_resize_image(path+image, TARGET_W_H)\n",
        "    img=np.array(img)/255\n",
        "    img=img.reshape(1, TARGET_W_H[1], TARGET_W_H[0], 1)\n",
        "    pred=encoder.predict(img)\n",
        "    pred=pred.reshape(-1)\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_IWBCM-WERx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test['image_encoding']=df_test['Image'].map(encode_test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XCRJ6snYptT",
        "colab_type": "code",
        "outputId": "de252703-7404-4f04-a4fb-22911189310b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "df_test.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>image_encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6658</th>\n",
              "      <td>d509ce3e2.jpg</td>\n",
              "      <td>[0.028265195, 0.5033969, 0.014187057, 0.247651...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5946</th>\n",
              "      <td>bec2f30d5.jpg</td>\n",
              "      <td>[0.015536418, 0.5867194, 0.014556223, 0.581924...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4343</th>\n",
              "      <td>8b18358a2.jpg</td>\n",
              "      <td>[0.43523717, 0.4687406, 0.42616588, 0.44306695...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>1c7f0f337.jpg</td>\n",
              "      <td>[0.012962001, 0.10209691, 0.004889608, 0.17017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3752</th>\n",
              "      <td>7861b6fce.jpg</td>\n",
              "      <td>[0.019346505, 0.48799893, 0.016251186, 0.91839...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Image                                     image_encoding\n",
              "6658  d509ce3e2.jpg  [0.028265195, 0.5033969, 0.014187057, 0.247651...\n",
              "5946  bec2f30d5.jpg  [0.015536418, 0.5867194, 0.014556223, 0.581924...\n",
              "4343  8b18358a2.jpg  [0.43523717, 0.4687406, 0.42616588, 0.44306695...\n",
              "935   1c7f0f337.jpg  [0.012962001, 0.10209691, 0.004889608, 0.17017...\n",
              "3752  7861b6fce.jpg  [0.019346505, 0.48799893, 0.016251186, 0.91839..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "9A0GN8pXjLY4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    Calculate L1 distances"
      ]
    },
    {
      "metadata": {
        "id": "jjJR7X4vbllW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_distance(x1, top_k=5, df_train=df, df_test=df_test):\n",
        "    \n",
        "    # calculate distances\n",
        "    distances=[np.linalg.norm(np.abs(x1-encoding)) for encoding in df_train['encoding']]\n",
        "    ids=[idx for idx in df_train['Id']]\n",
        "    pairs=zip(ids, distances)\n",
        "    \n",
        "    # create dict with distances\n",
        "    distances={k:0 for k in ids}\n",
        "    for (idx, distance) in pairs:\n",
        "        if distances[idx]>distance or distances[idx]==0:\n",
        "            distances[idx]=distance\n",
        "            \n",
        "    # sort by value and pick top_k labels            \n",
        "    distances=OrderedDict(sorted(distances.items(), key=lambda t: t[1]))\n",
        "    distances=list(distances.keys())[:top_k]\n",
        "    result=[label for label in distances]\n",
        "    \n",
        "    return ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0u5_j-y2nNbZ",
        "colab_type": "code",
        "outputId": "3ab5004b-b561-455b-d0e7-8f3826aabd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# # pandas.map with progress bar\n",
        "# # https://stackoverflow.com/questions/52153037/how-to-use-tqdm-with-map-for-dataframes\n",
        "\n",
        "# tqdm.pandas() # looks terrible in colab notebooks\n",
        "# df_test['Id']=df_test['image_encoding'].progress_map(calculate_distance)\n",
        "df_test['Id']=df_test['image_encoding'].map(calculate_distance)\n",
        "print('Test images are encoded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test images are encoded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GvMG9_cr5M62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# images with top 5 predicted labels\n",
        "subs=df_test[['Image','Id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-y5M8glJLMT",
        "colab_type": "code",
        "outputId": "65813968-bfc6-482a-9e6b-858c9ce8becd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "subs.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00028a005.jpg</td>\n",
              "      <td>w_cf8ce56 w_edce644 w_3a241cf new_whale w_f602022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000dcf7d8.jpg</td>\n",
              "      <td>w_f0fe284 new_whale w_700ebb4 w_698fcbe w_8cee3d3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000e7c7df.jpg</td>\n",
              "      <td>w_70d0b3c w_14461a7 w_4c218b5 w_ae6ac74 w_e16924b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0019c34f4.jpg</td>\n",
              "      <td>w_c158581 w_bd1c3d5 w_d875f4d w_7547b9a w_093d284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001a4d292.jpg</td>\n",
              "      <td>w_d1e0f06 new_whale w_697c75f w_3d67c3b w_aaf3463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Image                                                 Id\n",
              "0  00028a005.jpg  w_cf8ce56 w_edce644 w_3a241cf new_whale w_f602022\n",
              "1  000dcf7d8.jpg  w_f0fe284 new_whale w_700ebb4 w_698fcbe w_8cee3d3\n",
              "2  000e7c7df.jpg  w_70d0b3c w_14461a7 w_4c218b5 w_ae6ac74 w_e16924b\n",
              "3  0019c34f4.jpg  w_c158581 w_bd1c3d5 w_d875f4d w_7547b9a w_093d284\n",
              "4  001a4d292.jpg  w_d1e0f06 new_whale w_697c75f w_3d67c3b w_aaf3463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "6FkIih5REE9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a submission file\n",
        "subs.to_csv('submissions.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JqgkHOkREVdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download submission file\n",
        "files.download('submissions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOrY0E2OJkDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}